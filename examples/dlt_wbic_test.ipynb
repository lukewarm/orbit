{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a5b7d5",
   "metadata": {},
   "source": [
    "# Model Selection with WBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d5a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0dev\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import orbit\n",
    "print(orbit.__version__)\n",
    "from orbit.models import DLT\n",
    "from orbit.utils.simulation import make_trend, make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "organic-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0dev'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "variable-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff376c50",
   "metadata": {},
   "source": [
    "Generate a regression problem with trend with `8` number of regressors where only `3` of them are effective. First, generate the `3` effective regressors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af05537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,) (100, 3)\n"
     ]
    }
   ],
   "source": [
    "NUM_OF_REGRESSORS = 8\n",
    "NUM_OF_EFFECTIVE_REGRESSORS = 3\n",
    "SERIES_LEN = 100\n",
    "SEED = 20210101\n",
    "# sample some coefficients\n",
    "COEFS = np.random.default_rng(SEED).uniform(-1, 1, NUM_OF_EFFECTIVE_REGRESSORS)\n",
    "trend = make_trend(SERIES_LEN, rw_loc=0.01, rw_scale=0.1)\n",
    "x, regression, coefs = make_regression(series_len=SERIES_LEN, coefs=COEFS)\n",
    "print(regression.shape, x.shape)\n",
    "\n",
    "# combine trend and the regression\n",
    "y = trend + regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c248509c",
   "metadata": {},
   "source": [
    "We can add `5` irrelevant regressors into the dataset to add challenge in selecting the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac863f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n"
     ]
    }
   ],
   "source": [
    "x_extra = np.random.normal(0, 1, (SERIES_LEN, NUM_OF_REGRESSORS - NUM_OF_EFFECTIVE_REGRESSORS))\n",
    "x = np.concatenate([x, x_extra], axis=-1)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba0c5bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = [f\"x{x}\" for x in range(1, NUM_OF_REGRESSORS + 1)]\n",
    "response_col = \"y\"\n",
    "dt_col = \"date\"\n",
    "obs_matrix = np.concatenate([y.reshape(-1, 1), x], axis=1)\n",
    "# make a data frame for orbit inputs\n",
    "df = pd.DataFrame(obs_matrix, columns=[response_col] + x_cols)\n",
    "# make some dummy date stamp\n",
    "dt = pd.date_range(start='2016-01-04', periods=SERIES_LEN, freq=\"1W\")\n",
    "df['date'] = dt\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76443870",
   "metadata": {},
   "outputs": [],
   "source": [
    " regressor_col = x_cols[:3 + 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "split-warning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient evaluation took 0.000301 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 3.01 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "Gradient evaluation took 0.000238 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 2.38 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "\n",
      "Gradient evaluation took 0.000247 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 2.47 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "\n",
      "Gradient evaluation took 0.000243 seconds\n",
      "1000 transitions using 10 leapfrog steps per transition would take 2.43 seconds.\n",
      "Adjust your expectations accordingly!\n",
      "\n",
      "\n",
      "Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Iteration:    1 / 2000 [  0%]  (Warmup)\n",
      "Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Iteration:  200 / 2000 [ 10%]  (Warmup)\n",
      "Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Iteration:  400 / 2000 [ 20%]  (Warmup)\n",
      "Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Iteration:  600 / 2000 [ 30%]  (Warmup)\n",
      "Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Iteration:  800 / 2000 [ 40%]  (Warmup)\n",
      "Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Iteration: 1000 / 2000 [ 50%]  (Warmup)\n",
      "Iteration: 1001 / 2000 [ 50%]  (Sampling)\n",
      "Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Iteration: 1200 / 2000 [ 60%]  (Sampling)\n",
      "Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 3.61703 seconds (Warm-up)\n",
      "               0.442576 seconds (Sampling)\n",
      "               4.05961 seconds (Total)\n",
      "\n",
      "Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Iteration: 1400 / 2000 [ 70%]  (Sampling)\n",
      "Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 3.69156 seconds (Warm-up)\n",
      "               0.457104 seconds (Sampling)\n",
      "               4.14866 seconds (Total)\n",
      "\n",
      "Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Iteration: 1600 / 2000 [ 80%]  (Sampling)\n",
      "Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Iteration: 1800 / 2000 [ 90%]  (Sampling)\n",
      "Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 3.89721 seconds (Warm-up)\n",
      "               0.436562 seconds (Sampling)\n",
      "               4.33377 seconds (Total)\n",
      "\n",
      "Iteration: 2000 / 2000 [100%]  (Sampling)\n",
      "\n",
      " Elapsed Time: 3.9337 seconds (Warm-up)\n",
      "               0.455789 seconds (Sampling)\n",
      "               4.38948 seconds (Total)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<orbit.forecaster.full_bayes.FullBayesianForecaster at 0x13887ba90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlt_mod = DLT(\n",
    "        response_col=response_col,\n",
    "        date_col=dt_col,\n",
    "        regressor_col=regressor_col,\n",
    "        seed=2020,\n",
    "        # fixing the smoothing parameters to learn regression coefficients more effectively\n",
    "        level_sm_input=0.01,\n",
    "        slope_sm_input=0.01,\n",
    "        num_warmup=4000,\n",
    "        num_sample=4000,\n",
    "\n",
    "    )\n",
    "\n",
    "dlt_mod.fit(df=df, sampling_temperature = np.log(100.0)) #, sampling_temperature = 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "numerous-trigger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-165.74165349090822"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = dlt_mod.get_WBIC()\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ForecasterException: Model class: <class 'orbit.template.dlt.DLTModel'> is incompatible with \n",
    "        Estimator: <class 'orbit.estimators.stan_estimator.StanEstimatorMCMC'>.  \n",
    "            Estimator Support: [<class 'orbit.estimators.stan_estimator.StanEstimatorMAP'>, \n",
    "                                <class 'orbit.estimators.stan_estimator.StanEstimatorMCMC'>\n",
    "                                <class 'orbit.estimators.stan_estimator.StanEstimatorMCMC'>]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2dbc2",
   "metadata": {},
   "source": [
    "Now, we can calculate WBIC and compare them across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "wbics = np.empty(NUM_OF_REGRESSORS)\n",
    "\n",
    "for idx in range(NUM_OF_REGRESSORS):\n",
    "    regressor_col = x_cols[:idx + 1]\n",
    "\n",
    "    dlt_mod = DLT(\n",
    "        response_col=response_col,\n",
    "        date_col=dt_col,\n",
    "        regressor_col=regressor_col,\n",
    "        seed=2020,\n",
    "        # fixing the smoothing parameters to learn regression coefficients more effectively\n",
    "        level_sm_input=0.01,\n",
    "        slope_sm_input=0.01,\n",
    "        num_warmup=4000,\n",
    "        num_sample=4000,\n",
    "    )\n",
    "    dlt_mod.fit(df=df)\n",
    "    wbic = dlt.get_training_metrics()['WBIC']\n",
    "    print('Regressors:{} WBIC:{:.5f}'.format(regressor_col, wbic))\n",
    "    wbics[idx] = wbic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4f5bd",
   "metadata": {},
   "source": [
    "We plot the chart with WBICs against number of regressors included.  As we can see, WBIC is lowest when regressors overlapped exactly with the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c15a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "ax.plot(np.arange(1, NUM_OF_REGRESSORS + 1), wbics, color='dodgerblue', label='WBICs')\n",
    "ax.axvline(x=3, linestyle='--', color='orange', label='truth')\n",
    "ax.set_xlabel('Number of Regressors')\n",
    "ax.set_ylabel('WBIC')\n",
    "ax.set_title('Model Selection with WBIC')\n",
    "fig.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p37",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
